\section{Implementierung des Entscheidungsbaums}\label{sec:implementierung}
Das Programm implementiert den zuvor beschriebenen Algorithmus in der Programmiersprache Java.
Lediglich um Kommandozeilenparameter angenehmer einzupflegen wird eine Bibliothek verwendet.

\subsection{Aufbau}
Der Aufbau des Programms ist in \autoref{fig:klasse} dargestellt.
Um die Übersichtlichkeit nicht weiter Einzuschränkten wird auf die Darstellung der Funktionsparameter verzichtet.

\begin{figure}[ht!]
    \centering
    \resizebox{\textwidth}{!}{
        \input{assets/img/diagramme/klassendiagramm.latex}
    }
    \caption{Aufubau des Programms}
    \label{fig:klasse}
\end{figure}

\subsection{Ausführen des Programms}
\todoask[inline]{Anderer Dateiname?}
Im Anhang an diese Dokument befindet sich die Datei \enquote{tree.jar}.
Grundlegend kann das Programm, wie in \autoref{lst:jar-aufruf} gezeigt, aufgerufen werden.
Erforderlich ist hierfür zumindest Java in der Version 8.

\begin{lstlisting}[
    caption=Einfacher Aufruf des Programms,
    label=lst:jar-aufruf,
    language=bash
]
java -jar tree.jar
\end{lstlisting}

Durch verschiedene Parameter kann das Programm beeinflusst werden:
Die Parameter und ihre Standartwerte sind in folgdender Übersicht dargestellt.

\begin{description}
    \setlength\itemsep{-0.5em}
    \item[\texttt{-{}-teach, -t}]
        Datei, welche zum Trainieren genutzt wird\\
        Standard: \texttt{Wohnungskartei\_Muster\_Master\_5\_K\_teach.csv}
    \item[\texttt{-{}-check, -c}]
        Datei, welche mit dem Baum geprüft wird\\
        Standard: <leer>
    \item[\texttt{-{}-print, -p}]
        Wenn gesetzt, wird der Baum wie in \autoref{appendix:baum-training} dargestellt\\
        Standard: false
    \item[\texttt{-{}-default, -d}]
        Initiale Defaultwahrscheinlichkeit\\
        Standard: 0,5
    \item[\texttt{-{}-min-ratio, -r}]
        Mindestverhältnis zwischen Werten eines Attributs und Beispielmenge zur weiteren Unterteilung.\\
        Standard: 1
    \item[\texttt{-{}-use-saved-tree, -u}]
        Wenn gesetzt wird der Baum aus der angegebenen Datei geladen und nicht neu erzeugt.\\
        Standard: <leer>
    \item[\texttt{-{}-save-tree, -s}]
        Speichert den neu trainierten Baum in der angegebenen Datei.\\
        Standard: <leer>
    \item[\texttt{-{}-help}]
        Gibt die Hilfe in der Kommandozeile aus
\end{description}



\subsection{Besondere Aspekte}
\paragraph{Attribute}
Alle verfügbaren Attribute werden als \lstinline[language=Java]{enum} modelliert.
Jedes \lstinline[language=Java]{enum} gibt über die Funktion
\lstinline[language=Java]{getWerte()} die möglichen Ausprägungen als Liste von Zeichenketter zurück.

Auf diese Weise kann dass entsprechende Attribut as Parameter in Funktionsaufrufen übergeben werden und
innerhalb diese Funktion kann -- falls notwendig -- auf die möglichen Attributswerte zugegriffen werden.

\paragraph{Einlesen der Daten}
Weitestgehend werden die Daten direkt eingelesen und in ein \emph{Datensatz}-Objekt überführt.
Dieses Objekt enthält je ein Attribut für jedes der Merkmale und die Bewertung.
Für das Merkmal \enquote{Heizung} und für die Bewertung sind jedoch Schritte zur Vorverarbeitung notwendig:

Aus dem Zeichenketten \enquote{ja} und \enquote{nein} der Bewertung wird der entsprechende boolesche Wert ermittel.
In der Attributsausprägung \enquote{Lueftungsheizung} enthält der Datensatz anstatt des \textit{ue} ein undefiniertes Zeichen.
Dieses Problem wird dadurch gelöst, dass der Wert wie in \autoref{lst:heizung} angepasst wird.
Zwar wäre auch eine einmalige Änderung der entsprechende Werte in der Beispieldatei möglich,
die Programmzeile gestattet es aber auch, dass andere Dateien mit gleicher Formatierung bedenkenlos genutzt werden können.

\begin{lstlisting}[
    firstnumber=54,
    stepnumber=54,
    caption={Anpassen von \enquote{Heizung}},
    label=lst:heizung,
    language=Java
]
heizung = heizung.endsWith("ftungsheizung") ?
                    "Lueftungsheizung" :
                    heizung;
\end{lstlisting}

\paragraph{Datensatz}
Ein Datensatz-Objekt enthält für jeden relevanten Merkmalstyp eine Zeichenkette mit entsprechenden Namen.
Um dynamisch den Wert eines bestimmten Attributs zu erhalten kann dieses über die Funktion \lstinline[language=Java]{get()}
in \autoref{lst:datensatz-get} erfragt werden.

\lstinputlisting[
    caption={\texttt{get}-Funktion des Datensatzes (gekürzt)},
    label=lst:datensatz-get,
    language=Java
]{datensatz_get.java}

Für alle \enquote{normalen} Attribute wird der entsprechende Wert des Datensatzes zurückgegben.
Da die Bewertung ein boolescher Wert ist, die Funktion aber eine Zeichenkette zurückgeben muss,
wird dieser Wert entsprechend in eine Konstante umgewandelt.

\paragraph{Spezialisierung}
Das vorliegende Programm ist vor alle durch die Attribute und den Datensatz stark auf den gegebenen Anwendungsfall spezialisiert.
Theoretisch wäre es möglich ein Programm zu so konzipieren, dass es die Attribute und deren Wertemenge selbstständig aus den vorliegenden Daten extrahiert.
Dies würde jedoch die Komplexität und damit die Fehleranfälligkeit des Programms deutlich erhöhen.

\paragraph{Rekursionen}
Zum Erstellen des Baumes, aber auch zu Evaulation eines Datensatzes und zum Darstellen des Baumes wird Rekursion genutzt.
Beim Erstellen wird ein Attribut ausgewählt, und für jede Ausprägung ein Unterbaum nach gleiche Muster gebildet bis eine Enebedingung erreicht ist.
Details hierzu sind in \autoref{alg:baum-erzeugen} dargestellt.

Das \enquote{Ausdrucken} des Baums geschieht,
indem erst die Daten des aktuellen Knotens und
dann nach und nach die Daten der Unterbäume zu einer Zeichenkette hinzugefügt werden.

Um den Wert eines neuen Datensatzes zu ermitteln wird ausgehend von der Wurzel in jedem Knoten der zugehörige Attributswert aus dem Datensatz ausgelesen.
Dann wird die Bestimmungsfunktoin des zu diesem Wert zugehörige Unterbaums aufgerufen.
Dies geschieht rekursiv bis ein Blattknoten erreicht und damit der ermittelt ist.

\subsection{Test und Ergebnisbewertung}
Um den Algorithmus zu Testen und dessen Ergebnisse zu bewerten wird er in verschiedenen Konfigurationen ausgeführt (siehe \autoref{tab:run-config}).


\useunder{\uline}{\ul}{}
\begin{table}[h]
    \begin{center}
        \begin{tabular}{|l|l|l|l|}
        \hline
                               & {\ul \textbf{Trainingsdaten}} & {\ul \textbf{Testdaten}}      & {\ul \textbf{Verhältnis}} \\
            \hline
            T0                  & \dots 5\_K\_teach.csv & \dots 4\_K.csv        & $0$ \\
            \hline
            T1                  & \dots 5\_K\_teach.csv & \dots 4\_K.csv        & $1$ \\
            \hline
            T2                  & \dots 5\_K\_teach.csv & \dots 4\_K.csv        & $2$ \\
            \hline
            \hline
            C0                  & \dots 4\_K.csv        & \dots 5\_K\_teach.csv & $0$ \\
            \hline
            C1                  & \dots 4\_K.csv        & \dots 5\_K\_teach.csv & $1$ \\
            \hline
            C2                  & \dots 4\_K.csv        & \dots 5\_K\_teach.csv & $2$ \\
            \hline
        \end{tabular}
        \caption{Konfigurationen zur Ausführung}
        \label{tab:run-config}
    \end{center}
\end{table}

\paragraph{Genauigkeit der Klassifikation}
Die Genauigkeit der Klassifikation der jeweiligen Bäume wird bestimmt,
indem sowohl für die Trainings- als auch für die Testdaten eine Klassifikation ermittelt wird.
Die Ist-Klassifikation wird dann mit der Soll-Klassifikation verglichen.
Als Ergebnis wird der Anteil der korrekt Klassifizierten Datensätze herausgegeben.
Da das Ergebnis der Klassifikation eine Zahl zwischen $0$ und $1$ ist,
gilt jeder Wert $\geq 0.5$ als positive und jeder Wert $< 0.5$ als negative Klassifikation.
Es ergeben sich die in \autoref{tab:run-results} dargestellten Ergebnisse:

\useunder{\uline}{\ul}{}
\begin{table}[h]
    \begin{center}
        \begin{tabular}{|l|l|l|l|}
        \hline
                                & {\ul \textbf{Ergebnis Trainingsdaten}} & {\ul \textbf{Ergebnis Testdaten}} \\
            \hline
            T0                  & $100\%$                                & $\approx 98,901\%$                  \\
            \hline
            T1                  & $99,75\%$                              & $\approx 98,901\%$                  \\
            \hline
            T2                  & $99\%$                                 & $\approx 98,601\%$                  \\
            \hline
            \hline
            C0                  & $100\%$                                & $98,5\%$                  \\
            \hline
            C1                  & $100\%$                                & $98,5\%$                  \\
            \hline
            C2                  & $\approx 99,4\%$                       & $97,5\%$                  \\
            \hline
        \end{tabular}
        \caption{Anteil korrekt klasifizerter Datensätze}
        \label{tab:run-results}
    \end{center}
\end{table}

Die Durchläufe mit dem Mindestverhältnis $2$ (T2, C2) scheiden im Vergleich sowohl bei den Test- als auch bei den Trainingsdaten am schlechtsten ab.
Bei einem Mindestverhältnis von $0$ (T0, C0) ist das Abbruchkriterium quasi nicht vorhanden.
In diesem Fall werden die Trainingsdaten exakt nachgebildet,
was bedeutet, dass alle Trainingsdaten korrekt klassifiziert werden.

Im Fall der Konfiguration 2 mit einem Mindestverhältnis von $1$ (T1, C1) werden verglichen mit Konfiguration 1 in den Testdaten $0.25\%$ weniger korrekt klassifiziert.
Der Anteil der korrekt klassifizierten Testdaten bleibt jedoch gleich.
Daraus lässt sich schließen,
dass der Baum allgemeiner ist was einer Überanpassung entgegenwirkt.

\paragraph{Fehleranalyse}
In \autoref{tab:run-results} wird gezeigt, dass die Klassifikation insgesamt ein zufriedenstellendes Ergebnis liefert.
Je nach Anwendungsfall ist jedoch zu unterscheiden,
ob ein falsch klassifizierter Datensatz ein \emph{False Positive} oder ein \emph{False Negative} ist.

In \autoref{tab:fehleranalyse} sind die tatsächlichen Klassifikationen von T1 und C1 dargestellt.
Für T1 gibt es lediglich \emph{False Postives}, jedoch sowohl für die Trainings,
als auch die Testdaten.
Im Fall von C1 werden alle Trainingsdaten korrekt klasifizert,
allerdings entstehen in den Testdaten sowohl \emph{False Positives}, als auch ein \emph{False Negative}.

Welcher der beiden Fehler schwerer wiegt hängt vom Anwendungdfall ab.
Geht man in dem gegebenen Beispiel von einem Makler aus,
so sind vermutlich \emph{False Negatives} gravieredner.
Bieter der Makler diese nicht dem Kunden an,
so kann der Kunde sich logischerweiße nicht für die Wohnung entscheiden.

Da die Klassifikation keine \enquote{Ja-Nein}-Entscheidung trifft,
sondern eine Zahl zwischen $0$ und $1$ zurückgibt,
kann die Art des Fehlers beeinflusst werden.
Nimmt man beispielsweise an,
dass ein Datensatz bereits ab $0,3$ als positiv klassifiziert wird,
so steigt die Anzahl der \emph{False Positives}.

\useunder{\uline}{\ul}{}
\begin{table}[h]
	\begin{center}
		\begin{tabular}{|c|c|c|}
			\hline
			                        & {\ul \textbf{T1}} & {\ul \textbf{C1}}   \\
			\hline
			{\ul \textbf{Trainingsdaten}}       &
			{        \begin{tabular}{|l|l|l|}
			\hline
			{\ul \textbf{Ist/Soll}} & {\ul \textbf{Ja}} & {\ul \textbf{Nein}} \\
			\hline
			{\ul \textbf{Ja}}       & $68$              & $1$                 \\
			\hline
			{\ul \textbf{Nein}}     & $0$               & $331$               \\
			\hline
		\end{tabular}}
		&            {
        \begin{tabular}{|l|l|l|}
			\hline
			{\ul \textbf{Ist/Soll}} & {\ul \textbf{Ja}} & {\ul \textbf{Nein}} \\
			\hline
			{\ul \textbf{Ja}}       & $65$              & $0$                 \\
			\hline
			{\ul \textbf{Nein}}     & $0$               & $936$               \\
			\hline
		\end{tabular}}                 \\
		\hline
		{\ul \textbf{Testdaten}}     &            {
        \begin{tabular}{|l|l|l|}
			\hline
			{\ul \textbf{Ist/Soll}} & {\ul \textbf{Ja}} & {\ul \textbf{Nein}} \\
			\hline
			{\ul \textbf{Ja}}       & $65$              & $11$                 \\
			\hline
			{\ul \textbf{Nein}}     & $0$               & $925$               \\
			\hline
		\end{tabular}}               &            {
         \begin{tabular}{|l|l|l|}
			\hline
			{\ul \textbf{Ist/Soll}} & {\ul \textbf{Ja}} & {\ul \textbf{Nein}} \\
			\hline
			{\ul \textbf{Ja}}       & $67$              & $5$                 \\
			\hline
			{\ul \textbf{Nein}}     & $1$               & $327$               \\
			\hline
		\end{tabular}}               \\
		\hline
		\end{tabular}
		\caption{Fehleranalyse}
		\label{tab:fehleranalyse}
	\end{center}
\end{table}

\paragraph{Auswirkungen des Mindestverhältnis}
Die Entscheidungsbäume von T0 und T1 unterscheiden sich in in dem Unterbaum
\emph{Schule (nah)} $\rightarrow$ \emph{Moebeliert (nein)} $\rightarrow$ \emph{Zimmerzahl (4)} $\rightarrow$ \emph{Kindergarten (nah)} $\rightarrow$ \emph{Kehrwoche (ja)}.
\autoref{tab:diff} zeigt diesen Unterschied.

\useunder{\uline}{\ul}{}
\begin{table}[h]
    \begin{center}
        \begin{tabular}{|p{6cm}|p{6cm}|}
        \hline
            {\ul \textbf{T0}}   & {\ul \textbf{T1}} \\
            \hline
            {\lstinputlisting[
                language={},
                numbers=none,
                backgroundcolor=\color{white},
                frame=none
            ]{unterbaum_t0.txt}}
            &
            {\lstinputlisting[
                language={},
                numbers=none,
                backgroundcolor=\color{white},
                frame=none
            ]{unterbaum_t1.txt}}
            \\
            \hline
        \end{tabular}
        \caption{Unterschiede bei Mindestverhältnis von $0$ und $1$}
        \label{tab:diff}
    \end{center}
\end{table}

Betrachtet man die eigentlichen Trainingsdaten so finden sich lediglich zwei Datensätze.
Diese unterscheiden sich in den Attributen \emph{Stockwerk, Heizung, S-Bahn, Miete, Nebenkosten, Alter, Lage, Entfernung, Kaution, Bad, Balkon} und \emph{Quadratmeter}
Die Auswahl von \emph{Stockwerk} in T0, liegt also nicht daran,
dass es das beste Merkmal ist, sondern an der Reihenfolge der Merkmale.
Mit lediglich zwei Datensätzen, welche sich in so vielen Attributen voneinander unterscheiden,
kann nicht mit Sicheheit bestimmt werden welches Attribut ausschlaggebend für die Entscheidung des Kunden ist.
Um eine Überanpassung zu verhindern ist es daher sinnvoll diesen Unterbaum nicht weiter zu verzweigen.

\paragraph{Interpretation des Baumes}
Für T1 ergibt sich der in \autoref{appendix:baum-training} dargestellte Baum.
Er zeigt folgende Eigenschaften der Trainingsdaten:
\begin{itemize}
    \item Für die Kunden ist es unumgänglich, dass die Wohnung in Schulnähe und nicht möbeliert ist.
    \item Es kommen nur Wohnungen zwischen 3-4 und 5 Zimmern in Frage.
    \item Bei 3-4 bis 4-5 Zimmern darf die Wohnung nicht zu weit von einem Kindergarten entfernt sein.
    \item Ist eine 4-5 Zimmerwohnung in erreichbarer Nähe eines Kindergartens, so sollte sie nicht nur ein Waschbecken enthalten.
    \item Bei 5 Zimmern darf die Wohnung nicht über 120 Quadratmeter groß sein.
\end{itemize}

Aus diesen Eigenschaften lässt sich Interpretieren,
dass der Kunde eine Familie mit Schul- und wahrscheinlich Kindergartenkind(ern) ist.
Hauptindizien hierfür sind, die Nähe zu Schule und Kingergarten, sowie die Zimmerzahl.


Betrachtet man den Baum von C1 in \autoref{appendix:baum-test},
so finden sich diese Merkmale weitestgehen wieder.
Auch hier ist die Nähe zur Schule das wichtigste Merkmal.
Allerdings folgt dann die Zimmerzahl (wieder mit 3-4 bis 5 Zimmern).
Erst dann folgen - je nach Zimmerzahl in unterschiedlichen Reihenfolgen - die Kindergartennähe,
das Bad, und die Möbelierung.
Interesanterweiße kommen in zwei Fällen die Attribute Kaution beziehungweise die Art der Heizung hinzu.
